{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"learned_emb_model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hbNTILxfTpTS"},"source":["# French to English Machine Translation  \n","## Seq2Seq with attention & learned embeddings "]},{"cell_type":"markdown","metadata":{"id":"b-zBMDqH1Dh0"},"source":["Import Libraries"]},{"cell_type":"code","metadata":{"id":"TWmY82DcY1Wn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7eb1775-d563-4717-816b-d845ce2ee99e"},"source":["!pip install bcolz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bcolz\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.5)\n","Building wheels for collected packages: bcolz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BzRfkzlyzGUN"},"source":["!pip install translate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGS7GnX8cK7G"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import os, pickle, collections, bcolz\n","import operator\n","import itertools \n","import gensim\n","from termcolor import colored\n","from translate import Translator\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTxV64RKESs1"},"source":["ANSI Color Codes"]},{"cell_type":"code","metadata":{"id":"KCHdcO6DEUtP"},"source":["bold_blue_font_tag = '\\x1b[1m\\x1b[34m'\n","bold_red_font_tag = '\\x1b[1m\\x1b[31m'\n","red_font_tag = '\\u001b[31m'\n","bold_green_font_tag = '\\x1b[1m\\x1b[32m'\n","magenta = '\\033[35m'\n","bold = '\\033[1m'\n","reset = '\\033[0m'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NxQGUM7O1FQe"},"source":["Mount Drive"]},{"cell_type":"code","metadata":{"id":"2nQLXyxJgV4K"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pi92GVRXdSps"},"source":["Set the path to these files. They should be in the shared folder. Copy to your drive, or upload to colab instance."]},{"cell_type":"code","metadata":{"id":"H21QoI2MCjxr"},"source":["# dataset\n","dataset_path = '/content/drive/My Drive/MT/eng-fra.txt'\n","\n","# model weights\n","encoder_weights_path = '/content/drive/My Drive/encoder1_250000_0.0955.pth'\n","decoder_weights_path = '/content/drive/My Drive/attn_decoder1_250000_0.0955.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ec-UKQQN1GsF"},"source":["Make sure GPU is available"]},{"cell_type":"code","metadata":{"id":"gaXqqV51_gFf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606774785300,"user_tz":300,"elapsed":1322,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"fda3cbef-34b7-4a96-e27c-261b98189384"},"source":["torch.cuda.is_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Dbs8gFaI1JJi"},"source":["Create class to create vocab dictionaries"]},{"cell_type":"code","metadata":{"id":"qWoJwmC1cK7J"},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R6d7mLUb1a3p"},"source":["Preprocess text: lowercase, remove some punc., convert to Ascii"]},{"cell_type":"code","metadata":{"id":"88Nzd4f1cK7M"},"source":["# Turn a Unicode string to plain ASCII, thanks to\n","# https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sM_er7DX1lAN"},"source":["Function to read sentences, preprocess text, create vocab dictionaries"]},{"cell_type":"code","metadata":{"id":"113KR-wYcK7P"},"source":["def readLangs(reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open(dataset_path, encoding='utf-8').read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang('fra')\n","        output_lang = Lang('eng')\n","    else:\n","        input_lang = Lang('eng')\n","        output_lang = Lang('fra')\n","\n","    return input_lang, output_lang, pairs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YI3n_WTG136n"},"source":["Filtering dataset by length and prefix"]},{"cell_type":"code","metadata":{"id":"LSXmvzAzcK7R"},"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","      \n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN-C35pt17iz"},"source":["Calling everything above to prepare data"]},{"cell_type":"code","metadata":{"id":"o5UZvCZacK7W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606774793593,"user_tz":300,"elapsed":7022,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"222eb75a-737a-44f1-8f28-43555043ce01"},"source":["def prepareData(reverse=False):\n","    input_lang, output_lang, pairs = readLangs(reverse)\n","    pre_len = len(pairs)\n","    print(\"\\nRead %s sentence pairs\" % pre_len)\n","    pairs = filterPairs(pairs)\n","    post_len = len(pairs)\n","    print(f'Trimmed to {post_len} sentence pairs ')\n","    print(f'Using {post_len/pre_len * 100:.2f}% of dataset')\n","\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData(True)\n","print(f'\\nExample pair of sentences: {random.choice(pairs)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading lines...\n","\n","Read 135842 sentence pairs\n","Trimmed to 10599 sentence pairs \n","Using 7.80% of dataset\n","\n","Example pair of sentences: ['je suis desolee de vous avoir blesses .', 'i m sorry i hurt you .']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GZgm0vbr3Fdw"},"source":["Class for encoder"]},{"cell_type":"code","metadata":{"id":"LvFjh46ncK7Z"},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1lnCIV-3MUb"},"source":["Class for decoder with attention"]},{"cell_type":"code","metadata":{"id":"KFVcGyGkcK7f"},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8YF2gYF3ggV"},"source":["Converting to tensors"]},{"cell_type":"code","metadata":{"id":"cMHtL8y5cK7h"},"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9kiLobB3k7_"},"source":["Training function"]},{"cell_type":"code","metadata":{"id":"SzlcdNlScK7k"},"source":["teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"khj-xZjx3pd0"},"source":["Functions to keep track of time"]},{"cell_type":"code","metadata":{"id":"lkW8qaLRcK7n"},"source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rgt73wZ13sdd"},"source":["Function to run training"]},{"cell_type":"code","metadata":{"id":"0o956_VAcK7p"},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)\n","    return plot_losses"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SwU4mb0Q30bp"},"source":["Plot loss curve after training"]},{"cell_type":"code","metadata":{"id":"XIuDWzv6cK7s"},"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7RVKkrR34uX"},"source":["Function to evaluate after training"]},{"cell_type":"code","metadata":{"id":"jhEqrzfncK7u"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGqVSHVs380E"},"source":["Calculating bleu score"]},{"cell_type":"code","metadata":{"id":"OZOD5-adZYTO"},"source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","def bleu(reference,candidate):\n","  one_gram = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n","  return (one_gram)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uw6IUwJzYHB_"},"source":["Calculating Gleu score"]},{"cell_type":"code","metadata":{"id":"XWGiS2VNV-1Z"},"source":["from nltk.translate.gleu_score import sentence_gleu\n","\n","def gleu(reference, candidate):\n","  one_gram = sentence_gleu(reference, candidate)\n","  return (one_gram)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ReBUvyIC8yNY"},"source":["Custom score"]},{"cell_type":"code","metadata":{"id":"9v1KTaagWMP1"},"source":["# create a custom score by averaging bs and gs scores with weights\n","# adding a bonus if different words have a shared semantic meaning (cs score > 0.3)\n","# subtracting points if predicted sequence has duplicated words\n","# inputs: bleu score, gleu score, # of double words in pred\n","# outputs: custom score\n","\n","def custom_score(bs,gs,cs,double_word_penalty, verbose=True):\n","  total = ((bs*.75)+(gs*.25)) # weighted avg\n","  cs_bonus = 0\n","\n","  # calc cs bonus\n","  def get_bonus(cs,multiplier = .4):\n","    additional = 0\n","    for i in cs:\n","      additional += i * multiplier\n","    return additional\n","\n","  # if we have similarities, compute bonus\n","  if cs: \n","    cs_bonus = get_bonus(cs)\n","\n","\n","  # if perfect score, return 1\n","  if bs == 1:\n","    if verbose:\n","      print('\\nSemantic similarity bonus : +', float(cs_bonus))\n","      print('Double word penalty:        -', double_word_penalty * .1,'\\n')\n","    return 1.00\n","\n","  else:\n","    if cs_bonus:\n","      grand_total = total + cs_bonus\n","      if grand_total < 1:\n","        if verbose:\n","          print('\\nSemantic similarity bonus : +', float(cs_bonus))\n","          print('Double word penalty:        -', double_word_penalty * .1,'\\n')\n","        return grand_total\n","\n","      # bonus put score over 1  \n","      else:\n","        cs_bonus = get_bonus(cs, multiplier = .3)\n","        if verbose:\n","          print('\\nTotal score > 1, adjusting weights...') #debug statement, delete at end\n","          print('\\nSemantic similarity bonus : +', float(cs_bonus))\n","          print('Double word penalty:        -', double_word_penalty * .1,'\\n')\n","        grand_total = total + cs_bonus\n","        if grand_total < 1:   \n","          return grand_total\n","\n","        # bonus put score over 1   \n","        else:\n","          cs_bonus = get_bonus(cs, multiplier = .2)\n","          grand_total = total + cs_bonus\n","          if grand_total < 1:  \n","            return grand_total\n","          else:\n","            cs_bonus = get_bonus(cs, multiplier = .1)\n","            grand_total = total + cs_bonus\n","            if grand_total < 1:   \n","              return grand_total\n","\n","\n","\n","    # if no cs bonus      \n","    else:\n","      if verbose:\n","        print('\\nSemantic similarity bonus : +', float(cs_bonus))\n","        print('Double word penalty:        -', double_word_penalty * .1,'\\n')\n","      return total - (double_word_penalty * .1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RS7Xb3UpDaWl"},"source":["Fix output contractions"]},{"cell_type":"code","metadata":{"id":"AnWfLYADDZrP"},"source":["# fix issues with contractions when displaying results.\n","# issues: 's' could represent possesion and not 'is.' Small fraction of the time though.\n","# inputs: two lists of words\n","# outputs: two lists of words\n","\n","def fix_contractions(ref,pred):\n","  for idx, word in enumerate(pred):\n","    if word == 're':\n","      pred[idx] = 'are'\n","    elif word == 'm':\n","      pred[idx] = 'am' \n","    elif word == 's':\n","      pred[idx] = 'is'   \n","    elif word == 'ok':\n","      pred[idx] = 'okay'  \n","    elif (word == 'aren' and pred[idx+1] == 't'):\n","      pred[idx] = 'are' \n","      pred[idx+1] = 'not'\n","    elif (word == 'isn' and pred[idx+1] == 't'):\n","      pred[idx] = 'is' \n","      pred[idx+1] = 'not'\n","    elif (word == 'don' and pred[idx+1] == 't'):\n","      pred[idx] = 'do' \n","      pred[idx+1] = 'not'\n","\n","  for idx, rword in enumerate(ref):\n","    if rword == 're':\n","      ref[idx] = 'are'\n","    elif rword == 'm':\n","      ref[idx] = 'am' \n","    elif rword == 'ok':\n","      ref[idx] = 'okay'       \n","    elif rword == 's':\n","      ref[idx] = 'is'  \n","    elif (rword == 'aren' and ref[idx+1] == 't'):\n","      ref[idx] = 'are' \n","      ref[idx+1] = 'not'        \n","    elif (rword == 'isn' and ref[idx+1] == 't'):\n","      ref[idx] = 'is' \n","      ref[idx+1] = 'not' \n","    elif (rword == 'don' and ref[idx+1] == 't'):\n","      ref[idx] = 'do' \n","      ref[idx+1] = 'not' \n","\n","  return ref, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZJaqVh_9VZQ"},"source":["Fix Punctuation"]},{"cell_type":"code","metadata":{"id":"MIFXJRCr2UpD"},"source":["# sometimes ending punctuation is filtered off prediction when no EOS token is predicted\n","# adding it back in to not trigger missed prediction\n","# input: two lists of words\n","# output: two lists of words\n","\n","def fix_punctuation(ref, pred):\n","  ending_punc = [ref[-1]]\n","  if pred[-1] not in ending_punc:\n","    pred.append(ending_punc[0])\n","  return ref, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B3Ghxzmg4OKx"},"source":["Initialize models and start training"]},{"cell_type":"code","metadata":{"id":"wQD807FacK7y","colab":{"base_uri":"https://localhost:8080/","height":707},"executionInfo":{"status":"ok","timestamp":1606779361963,"user_tz":300,"elapsed":4547936,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"63ff1068-fc5c-4fd3-ad4a-a8adaf8328f9"},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","#trainIters(encoder1, attn_decoder1, 90000, print_every=5000)\n","loss_tracker = trainIters(encoder1, attn_decoder1, 250000, print_every=10000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3m 11s (- 76m 47s) (10000 4%) 2.5727\n","6m 17s (- 72m 21s) (20000 8%) 1.8617\n","9m 23s (- 68m 53s) (30000 12%) 1.4468\n","12m 29s (- 65m 36s) (40000 16%) 1.1702\n","15m 31s (- 62m 6s) (50000 20%) 0.9401\n","18m 30s (- 58m 36s) (60000 24%) 0.7839\n","21m 31s (- 55m 20s) (70000 28%) 0.6468\n","24m 31s (- 52m 7s) (80000 32%) 0.5575\n","27m 31s (- 48m 56s) (90000 36%) 0.4719\n","30m 32s (- 45m 48s) (100000 40%) 0.3963\n","33m 33s (- 42m 42s) (110000 44%) 0.3515\n","36m 34s (- 39m 37s) (120000 48%) 0.2872\n","39m 34s (- 36m 32s) (130000 52%) 0.2535\n","42m 34s (- 33m 27s) (140000 56%) 0.2357\n","45m 34s (- 30m 22s) (150000 60%) 0.2107\n","48m 36s (- 27m 20s) (160000 64%) 0.2001\n","51m 42s (- 24m 20s) (170000 68%) 0.1774\n","54m 42s (- 21m 16s) (180000 72%) 0.1664\n","57m 42s (- 18m 13s) (190000 76%) 0.1650\n","60m 41s (- 15m 10s) (200000 80%) 0.1536\n","63m 40s (- 12m 7s) (210000 84%) 0.1408\n","66m 41s (- 9m 5s) (220000 88%) 0.1345\n","69m 42s (- 6m 3s) (230000 92%) 0.1215\n","72m 44s (- 3m 1s) (240000 96%) 0.1184\n","75m 46s (- 0m 0s) (250000 100%) 0.1118\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"unc6dh1xUa8C"},"source":["Save losses for plotting"]},{"cell_type":"code","metadata":{"id":"NgFkl33tJsSI"},"source":["loss_tracker"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7fAtfXKJsWO"},"source":["with open('/content/scratch_w_attn.pkl', 'wb') as f:\n","  pickle.dump(loss_tracker, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfN36-uKOnKU","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1606779362722,"user_tz":300,"elapsed":733,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"0db05982-9771-43f7-b619-7bd6b0e8e3e9"},"source":["from google.colab import files\n","files.download('/content/scratch_w_attn.pkl') "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b3cd1a02-4383-477b-8284-7af647b2f01c\", \"scratch_w_attn.pkl\", 22512)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mbfGKl3_4XK2"},"source":["Load model weights from drive"]},{"cell_type":"code","metadata":{"id":"2V5wGhRvWvMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606187591195,"user_tz":300,"elapsed":6640,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"7d400513-347a-43b8-cb9f-1777da05d701"},"source":["encoder1.load_state_dict(torch.load(encoder_weights_path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"5Nvb0-ZAWvI8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606187591689,"user_tz":300,"elapsed":6404,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"7553a020-f461-4fe8-e266-e485dd9491d8"},"source":["attn_decoder1.load_state_dict(torch.load(decoder_weights_path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"AdMtVVmW4a7_"},"source":["Save weights after training"]},{"cell_type":"code","metadata":{"id":"uwzGKcwI3PiM"},"source":["#torch.save(encoder1.state_dict(), 'encoder1_0.3811.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CGd3Q_y3PlG"},"source":["#torch.save(attn_decoder1.state_dict(), 'attn_decoder1_0.3811.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qh8Xw-Zf9gUe"},"source":["Two new WE models for cosine sim.: word2vec and Finnish Parsebank"]},{"cell_type":"markdown","metadata":{"id":"kyXi7GwR_BFr"},"source":["Both these .bin files are in the shared drive"]},{"cell_type":"code","metadata":{"id":"2oUGy4ra0kOS"},"source":["# w2v WE model:\n","w2v_model = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/My Drive/Embedding Models/word2vec.bin', binary=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"445Xch2s9pp3"},"source":["Calculate cosine similiarities"]},{"cell_type":"code","metadata":{"id":"0BQHQocOlmY2"},"source":["# calculates penalties for double words, filters sentences to relevant words to compare,\n","# calculateds cos. sim., and a score for the strength of the cos. sims.\n","# inputs: two lists of words\n","# outputs: relevant word cosine sim. scores over 0.3, number of double words in the prediction\n","\n","def similarities(A,B,verbose=True):\n","\n","  # does B have more double words than A? \n","  doublesA = 0\n","  doublesB = 0\n","  basketA = []\n","  basketB = []\n","\n","  for i in A:\n","    if i not in basketA:\n","      basketA.append(i)\n","    else:\n","      doublesA += 1\n","\n","  for i in B: \n","    if i not in basketB:\n","      basketB.append(i)\n","    else:\n","      doublesB += 1\n","\n","  # calc penalty, keep only positive values\n","  double_word_penalty = np.clip(doublesB - doublesA, 0,3) \n","\n","  # get words not in the other sentence and not in punc/stopwords\n","  stop_words = ['a','an','of','the','to','on','t','in','as'] #,'not','no']\n","  punc = ['.','?','!',',']\n","  extraW = [] # all extra words\n","  extraA = []\n","  extraB = []\n","\n","  for i in A:\n","    if i not in punc:\n","      if i not in stop_words:\n","        if (i not in B):\n","          extraA.append(i)\n","  for i in B:\n","    if i not in punc:\n","      if i not in stop_words:\n","        if (i not in A):\n","          extraB.append(i)\n","\n","  extraW = extraA + extraB\n","\n","  # if off by one word, exit\n","  if len(extraW) == 1:\n","    return [0, double_word_penalty]\n","  \n","  # calc cos sims and score\n","  sim_finn = []\n","  sim_w2v = []\n","  record = []\n","\n","  for a, b in itertools.product(extraA,extraB):\n","    sim_w2v.append([a,b,w2v_model.similarity(a,b)])\n","\n","  sorted_sim_w2v = sorted(sim_w2v, key = lambda x: x[2], reverse=True)\n","\n","  cs_score = [0] #list of cs over 0.3\n","\n","  # print cs scores\n","  if sorted_sim_w2v:\n","    if verbose:\n","      print('\\nSemantic similarities using w2v:')\n","    for idx,i in enumerate(sorted_sim_w2v):\n","      if verbose:\n","        if i[2] > 0.3:\n","          print(bold, end=\"\")\n","          print('  ',i,reset)\n","        else:\n","          print('  ',i)\n","    #print('\\n')\n","    # record cs scores\n","    for i in sorted_sim_w2v:\n","      if i[2] > 0.3:\n","        cs_score.append(i[2])\n","\n","  return [cs_score, double_word_penalty]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"updxp9zFUgdA"},"source":["Google Translate API"]},{"cell_type":"code","metadata":{"id":"YK_yUoalXfLb"},"source":["# run text through google translate api\n","# input: string\n","# output: string\n","\n","def google_translate(text):\n","  translator= Translator(from_lang=\"french\",to_lang=\"english\")\n","  translation = translator.translate(text)\n","  return translation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ere-_31MUh7g"},"source":["Evalue whole dataset"]},{"cell_type":"code","metadata":{"id":"wfFwBl_Ac1K_"},"source":["# evaluate n random pairs from dataset\n","# input: models, n\n","# output: none\n","\n","def evaluateAll(encoder, decoder, n=1000, all = False):\n","    print(bold+'Evaluation of Machine Translation Models'+reset)\n","    \n","    #scratch\n","    bleu_score_tracker = []\n","    gleu_score_tracker = []\n","    custom_tracker = []\n","\n","    #glove\n","    glove_bleu_score_tracker = []\n","    glove_gleu_score_tracker = []\n","    glove_custom_tracker = []\n","\n","    record_test = []\n","    ending_punc = ['.','?','!']\n","\n","    if not all: # run on n randomly chosen pairs\n","      print(bold+'Evaluating ',n,' examples...'+reset)\n","\n","      # get random indices to pull data from\n","      rand_indices = [random.randint(0,len(pairs)-1) for i in range(n)]\n","\n","      for i in rand_indices:\n","\n","          pair = pairs[i]\n","          # create lookup table for pairs including idx for easy look up\n","          output_words, attentions = evaluate(encoder, decoder, pair[0])  \n","          \n","          ###### preprocess function#######\n","          ref = pair[1].split()#[:-1]\n","          pred = output_words[:-1]\n","\n","          # fix contractions\n","          ref, pred = fix_contractions(ref, pred)\n","\n","          # if missing ending punctuation\n","          if pred[-1] not in ending_punc:\n","            ref, pred = fix_punctuation(ref, pred) \n","\n","          ###### look up other model pred function#######\n","          # get glove prediction\n","          glove = glove_frwac_df['Prediction'][i] #************\n","\n","          ###### get scores function#######\n","          bleu_one_gram = bleu([ref[:-1]],pred[:-1])\n","          glove_bleu = bleu([ref[:-1]],glove[:-1])#************\n","\n","          # DO NOT DISPLAY PERFECT SCORES - USED FOR EASY DEBUGGING - DELETE AT END\n","          # CONVERT TO DISPLAYING PERFECT SCORES SOME FRACTION OF THE TIME (1/5TH?)\n","          if bleu_one_gram < 1:\n","            print('\\n')\n","            print(bold+'Input:\\t'+reset, pair[0])\n","            print(bold+'Target:\\t'+reset, ' '.join(ref))\n","\n","\n","            print(bold+'S-Pred:\\t'+reset, ' '.join(pred))\n","            print(bold+'G-Pred:\\t'+reset, ' '.join(glove),'\\n')#************\n","            \n","            # requires ref to be a 2d list, pred 1d list\n","            bleu_score_tracker.append(bleu_one_gram)\n","            gleu_one_gram = gleu([ref[:-1]],pred[:-1])\n","            gleu_score_tracker.append(gleu_one_gram)\n","            print(f'Scratch Bleu Score: {bleu_one_gram:.3f}')\n","            print(f'Scratch Gleu Score: {gleu_one_gram:.3f}')\n","            print(f'Scratch Avg Score:  {(gleu_one_gram*.25+bleu_one_gram*.75):.3f}') #weighted\n","\n","            glove_bleu_score_tracker.append(glove_bleu)#************\n","            glove_gleu = gleu([ref[:-1]],glove[:-1])#************\n","            glove_gleu_score_tracker.append(glove_gleu)#************\n","            print(f'Glove Bleu Score: \\t{glove_bleu:.3f}')\n","            print(f'Glove Gleu Score: \\t{glove_gleu:.3f}')\n","            print(f'Glove Avg Score:  \\t{(glove_gleu*.25+glove_bleu*.75):.3f}') #weighted\n","            \n","\n","            \n","            cs_score = 0\n","\n","            # if not perfect score: calc. bonuses and penalties\n","            if bleu_one_gram < 1:\n","              try: # sometimes sims returns none\n","                sim_returns = similarities(ref,pred)\n","                cs_score = sim_returns[0]\n","                double_word_penalty = sim_returns[1]\n","                cust_score = custom_score(bleu_one_gram,gleu_one_gram,cs_score,double_word_penalty)\n","                print(f'{bold_red_font_tag}S-Custom Score: {cust_score:.3f}{reset}')\n","\n","              # if word not in WE\n","              except KeyError:\n","                print('Cosine similarities: Word not found in embedding vocabulary')\n","                continue\n","            else:\n","              cust_score = custom_score(bleu_one_gram,gleu_one_gram,0,0)\n","              print(f'{bold_red_font_tag}S-Custom Score: {cust_score:.3f}{reset}')\n","\n","            custom_tracker.append(cust_score)\n","\n","\n","            if glove_bleu < 1:\n","              try: # sometimes sims returns none\n","                glove_sim_returns = similarities(ref,glove)\n","                glove_cs_score = glove_sim_returns[0]\n","                glove_double_word_penalty = glove_sim_returns[1]\n","                glove_cust_score = custom_score(glove_bleu,glove_gleu,glove_cs_score,glove_double_word_penalty)\n","                print(f'{bold_red_font_tag}G-Custom Score: {glove_cust_score:.3f}{reset}')\n","                #print('\\n')\n","\n","              # if word not in WE\n","              except KeyError:\n","                print('Cosine similarities: Word not found in embedding vocabulary')\n","                continue\n","            else:\n","              glove_cust_score = custom_score(glove_bleu,glove_gleu,0,0)\n","              print(f'{bold_red_font_tag}G-Custom Score: {glove_cust_score:.3f}{reset}')\n","\n","            glove_custom_tracker.append(glove_cust_score)\n","\n","\n","      print('\\n')\n","      print(f'{bold_blue_font_tag}Avg S-Bleu Score  :{reset} {sum(bleu_score_tracker)/len(bleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg S-Gleu Score  :{reset} {sum(gleu_score_tracker)/len(gleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg S-Custom Score:{reset} {sum(custom_tracker)/len(custom_tracker):.3f}')\n","\n","      print('\\n')\n","      print(f'{bold_blue_font_tag}Avg G-Bleu Score  :{reset} {sum(glove_bleu_score_tracker)/len(glove_bleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg G-Gleu Score  :{reset} {sum(glove_gleu_score_tracker)/len(glove_gleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg G-Custom Score:{reset} {sum(glove_custom_tracker)/len(glove_custom_tracker):.3f}')\n","\n","    else: # run on entire dataset\n","      print(bold+'Evaluating entire dataset...'+reset)\n","      for i in range(len(pairs)):\n","        pair = pairs[i]\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])  \n","        ref = pair[1].split()#[:-1]\n","        pred = output_words[:-1]\n","\n","        # fix contractions\n","        ref, pred = fix_contractions(ref, pred)\n","\n","        # if missing ending punctuation\n","        if pred[-1] not in ending_punc:\n","          ref, pred = fix_punctuation(ref, pred) \n","\n","        bleu_one_gram = bleu([ref[:-1]],pred[:-1])\n","        bleu_score_tracker.append(bleu_one_gram)\n","        gleu_one_gram = gleu([ref[:-1]],pred[:-1])\n","        gleu_score_tracker.append(gleu_one_gram)\n","\n","        cs_score = 0\n","\n","        # if not perfect score: calc. bonuses and penalties\n","        if bleu_one_gram < 1:\n","          try: # sometimes sims returns none\n","            sim_returns = similarities(ref,pred, verbose=False)\n","            cs_score = sim_returns[0]\n","            double_word_penalty = sim_returns[1]\n","            cust_score = custom_score(bleu_one_gram,gleu_one_gram,cs_score,double_word_penalty, verbose=False)\n","            #print(bold_red_font_tag+'Custom Score: ',cust_score,reset)\n","            #print('\\n')\n","\n","          # if word not in WE\n","          except KeyError:\n","            #print('Cosine similarities: Word not found in embedding vocabulary')\n","            continue\n","        else:\n","          cust_score = custom_score(bleu_one_gram,gleu_one_gram,0,0, verbose=False)\n","          #print(bold_red_font_tag+'Custom Score: ',cust_score,reset)\n","\n","        custom_tracker.append(cust_score)\n","\n","      print('\\n')\n","      print(f'{bold_blue_font_tag}Avg Bleu Score  :{reset} {sum(bleu_score_tracker)/len(bleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg Gleu Score  :{reset} {sum(gleu_score_tracker)/len(gleu_score_tracker):.3f}')\n","      print(f'{bold_blue_font_tag}Avg Custom Score:{reset} {sum(custom_tracker)/len(custom_tracker):.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8RM8n8FUlUR"},"source":["Load results from other models"]},{"cell_type":"code","metadata":{"id":"e3Ja6XtKcHjO"},"source":["with open('/content/drive/MyDrive/Embedding Models/glove_frwac_results.pkl', 'rb') as f:\n","  glove_frwac_results = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/Embedding Models/ft_frwac_results_V1.pkl', 'rb') as f:\n","  ft_frwac_results = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/Embedding Models/w2v_frwac_results_V2.pkl', 'rb') as f:\n","  w2v_frwac_results = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49wphMiHcU-V"},"source":["# Idx is the index of the sentence in the pairs dataset\n","\n","import pandas as pd\n","glove_frwac_df = pd.DataFrame(glove_frwac_results, columns=['Idx','Ref','Prediction'])\n","#glove_frwac_df.sample(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODdU1IfYS_lY"},"source":["#w2v_frwac_df = pd.DataFrame(w2v_frwac_results, columns=['Idx','Ref','Prediction'])\n","w2v_frwac_df.sample(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39bPlfHlS_gY"},"source":["ft_frwac_df = pd.DataFrame(ft_frwac_results, columns=['Idx','Ref','Prediction'])\n","#ft_frwac_df.sample(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjMmGG4CUn9R"},"source":["Evaluate n examples of pairs"]},{"cell_type":"code","metadata":{"id":"WbpDYJijNp78"},"source":["# evaluate n random pairs from dataset\n","# input: models, n\n","# output: none\n","\n","def evaluateRandomlySimplifiedOutput(encoder, decoder, n=1000):\n","    print(bold+'Evaluation of Machine Translation Models'+reset)\n","    \n","    #scratch\n","    bleu_score_tracker = []\n","    gleu_score_tracker = []\n","    custom_tracker = []\n","\n","    #glove\n","    glove_bleu_score_tracker = []\n","    glove_gleu_score_tracker = []\n","    glove_custom_tracker = []\n","\n","    #w2v\n","    w2v_bleu_score_tracker = []\n","    w2v_gleu_score_tracker = []\n","    w2v_custom_tracker = []\n","\n","    #ft\n","    ft_bleu_score_tracker = []\n","    ft_gleu_score_tracker = []\n","    ft_custom_tracker = []\n","\n","    record_test = []\n","    ending_punc = ['.','?','!']\n","\n","    print(bold+'Evaluating ',n,' examples...'+reset)\n","\n","    # get random indices to pull data from\n","    rand_indices = [random.randint(0,len(pairs)-1) for i in range(n)]\n","\n","    for i in rand_indices:\n","\n","        pair = pairs[i]\n","        # create lookup table for pairs including idx for easy look up\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])  \n","        \n","        ###### preprocess function#######\n","        ref = pair[1].split()#[:-1]\n","        pred = output_words[:-1]\n","\n","        # fix contractions\n","        ref, pred = fix_contractions(ref, pred)\n","\n","        # if missing ending punctuation\n","        if pred[-1] not in ending_punc:\n","          ref, pred = fix_punctuation(ref, pred) \n","\n","        ###### look up other model pred function#######\n","        # get glove prediction\n","        glove = glove_frwac_df['Prediction'][i] #************\n","\n","        # get w2v prediction\n","        w2v = w2v_frwac_df['Prediction'][i] #************\n","\n","        # get fasttext prediction\n","        ft = ft_frwac_df['Prediction'][i] #************\n","\n","\n","        ###### get scores function#######\n","        bleu_one_gram = bleu([ref[:-1]],pred[:-1])\n","        glove_bleu = bleu([ref[:-1]],glove[:-1])#************\n","        w2v_bleu = bleu([ref[:-1]],w2v[:-1])#************\n","        ft_bleu = bleu([ref[:-1]],ft[:-1])#************\n","\n","\n","        # DO NOT DISPLAY PERFECT SCORES - USED FOR EASY DEBUGGING - DELETE AT END\n","        # CONVERT TO DISPLAYING PERFECT SCORES SOME FRACTION OF THE TIME (1/5TH?)\n","        if bleu_one_gram < 1:\n","          print('\\n')\n","          print(bold+'Input:\\t'+reset, pair[0])\n","          print(bold+'Target:\\t'+reset, ' '.join(ref),'\\n')\n","\n","\n","          print(bold+'G-Pred:\\t'+reset, ' '.join(glove))#************\n","          print(bold+'W-Pred:\\t'+reset, ' '.join(w2v))#************\n","          print(bold+'F-Pred:\\t'+reset, ' '.join(ft))#************\n","          print(bold+'S-Pred:\\t'+reset, ' '.join(pred),'\\n')\n","\n","          # requires ref to be a 2d list, pred 1d list\n","          bleu_score_tracker.append(bleu_one_gram)\n","          gleu_one_gram = gleu([ref[:-1]],pred[:-1])\n","          gleu_score_tracker.append(gleu_one_gram)\n","\n","          glove_bleu_score_tracker.append(glove_bleu)#************\n","          glove_gleu = gleu([ref[:-1]],glove[:-1])#************\n","          glove_gleu_score_tracker.append(glove_gleu)#************\n","\n","          w2v_bleu_score_tracker.append(w2v_bleu)#************\n","          w2v_gleu = gleu([ref[:-1]],w2v[:-1])#************\n","          w2v_gleu_score_tracker.append(w2v_gleu)#************\n","\n","          ft_bleu_score_tracker.append(ft_bleu)#************\n","          ft_gleu = gleu([ref[:-1]],ft[:-1])#************\n","          ft_gleu_score_tracker.append(ft_gleu)#************\n","\n","          cs_score = 0\n","\n","          # if not perfect score: calc. bonuses and penalties\n","          if bleu_one_gram < 1:\n","            try: # sometimes sims returns none\n","              sim_returns = similarities(ref,pred,verbose=False)\n","              cs_score = sim_returns[0]\n","              double_word_penalty = sim_returns[1]\n","              cust_score = custom_score(bleu_one_gram,gleu_one_gram,cs_score,double_word_penalty,verbose=False)\n","\n","            # if word not in WE\n","            except KeyError:\n","              continue\n","          else:\n","            cust_score = custom_score(bleu_one_gram,gleu_one_gram,0,0,verbose=False)\n","\n","          custom_tracker.append(cust_score)\n","\n","          # glove\n","          if bleu_one_gram < 1:\n","            try: # sometimes sims returns none\n","              glove_sim_returns = similarities(ref,glove,verbose=False)\n","              glove_cs_score = glove_sim_returns[0]\n","              glove_double_word_penalty = glove_sim_returns[1]\n","              glove_cust_score = custom_score(glove_bleu,glove_gleu,glove_cs_score,glove_double_word_penalty,verbose=False)\n","\n","            # if word not in WE\n","            except KeyError:\n","              continue\n","          else:\n","            glove_cust_score = custom_score(glove_bleu,glove_gleu,0,0,verbose=False)\n","\n","          glove_custom_tracker.append(glove_cust_score)\n","\n","          # w2v\n","          if bleu_one_gram < 1:\n","            try: # sometimes sims returns none\n","              w2v_sim_returns = similarities(ref,w2v,verbose=False)\n","              w2v_cs_score = w2v_sim_returns[0]\n","              w2v_double_word_penalty = w2v_sim_returns[1]\n","              w2v_cust_score = custom_score(w2v_bleu,w2v_gleu,w2v_cs_score,w2v_double_word_penalty,verbose=False)\n","\n","            # if word not in WE\n","            except KeyError:\n","              continue\n","          else:\n","            w2v_cust_score = custom_score(w2v_bleu,w2v_gleu,0,0,verbose=False)\n","\n","          w2v_custom_tracker.append(w2v_cust_score)\n","\n","          # ft\n","          if bleu_one_gram < 1:\n","            try: # sometimes sims returns none\n","              ft_sim_returns = similarities(ref,ft,verbose=False)\n","              ft_cs_score = ft_sim_returns[0]\n","              ft_double_word_penalty = ft_sim_returns[1]\n","              ft_cust_score = custom_score(ft_bleu,ft_gleu,ft_cs_score,ft_double_word_penalty,verbose=False)\n","\n","            # if word not in WE\n","            except KeyError:\n","              continue\n","          else:\n","            ft_cust_score = custom_score(ft_bleu,ft_gleu,0,0,verbose=False)\n","\n","          ft_custom_tracker.append(ft_cust_score)\n","\n","          print(f'G-Scores:\\tBleu: {glove_bleu:.3f}\\tGleu: {glove_gleu:.3f}\\tCustom Score: {glove_cust_score:.3f}')\n","          print(f'W-Scores:\\tBleu: {w2v_bleu:.3f}\\tGleu: {w2v_gleu:.3f}\\tCustom Score: {w2v_cust_score:.3f}')\n","          print(f'F-Scores:\\tBleu: {ft_bleu:.3f}\\tGleu: {ft_gleu:.3f}\\tCustom Score: {ft_cust_score:.3f}')\n","          print(f'S-Scores:\\tBleu: {bleu_one_gram:.3f}\\tGleu: {gleu_one_gram:.3f}\\tCustom Score: {cust_score:.3f}')\n"," \n","\n","\n","    print('\\n')\n","    print(f'{bold_blue_font_tag}Avg G-Bleu Score  :{reset} {sum(glove_bleu_score_tracker)/len(glove_bleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg G-Gleu Score  :{reset} {sum(glove_gleu_score_tracker)/len(glove_gleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg G-Custom Score:{reset} {sum(glove_custom_tracker)/len(glove_custom_tracker):.3f}')\n","\n","    print('\\n')\n","    print(f'{bold_blue_font_tag}Avg W-Bleu Score  :{reset} {sum(w2v_bleu_score_tracker)/len(w2v_bleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg W-Gleu Score  :{reset} {sum(w2v_gleu_score_tracker)/len(w2v_gleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg W-Custom Score:{reset} {sum(w2v_custom_tracker)/len(w2v_custom_tracker):.3f}')\n","\n","    print('\\n')\n","    print(f'{bold_blue_font_tag}Avg F-Bleu Score  :{reset} {sum(ft_bleu_score_tracker)/len(ft_bleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg F-Gleu Score  :{reset} {sum(ft_gleu_score_tracker)/len(ft_gleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg F-Custom Score:{reset} {sum(ft_custom_tracker)/len(ft_custom_tracker):.3f}')\n","\n","    print('\\n')\n","    print(f'{bold_blue_font_tag}Avg S-Bleu Score  :{reset} {sum(bleu_score_tracker)/len(bleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg S-Gleu Score  :{reset} {sum(gleu_score_tracker)/len(gleu_score_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg S-Custom Score:{reset} {sum(custom_tracker)/len(custom_tracker):.3f}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZr2oEopUrFS"},"source":["Compare all models for n pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqIY6QNoXKJz","executionInfo":{"status":"ok","timestamp":1606191214035,"user_tz":300,"elapsed":9079,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"0348a6df-2cbe-4621-8740-7efd44f7f1f2"},"source":["evaluateRandomlySimplifiedOutput(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mEvaluation of Machine Translation Models\u001b[0m\n","\u001b[1mEvaluating  1000  examples...\u001b[0m\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle est six ans plus agee que moi .\n","\u001b[1mTarget:\t\u001b[0m she is six years older than me . \n","\n","\u001b[1mG-Pred:\t\u001b[0m she is teaching us two .\n","\u001b[1mW-Pred:\t\u001b[0m she is devoted to meet you .\n","\u001b[1mF-Pred:\t\u001b[0m she is a bit naive .\n","\u001b[1mS-Pred:\t\u001b[0m she is six years older than i am . \n","\n","G-Scores:\tBleu: 0.268\tGleu: 0.136\tCustom Score: 0.974\n","W-Scores:\tBleu: 0.282\tGleu: 0.136\tCustom Score: 0.473\n","F-Scores:\tBleu: 0.268\tGleu: 0.136\tCustom Score: 0.522\n","S-Scores:\tBleu: 0.750\tGleu: 0.692\tCustom Score: 0.859\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis raisonnable .\n","\u001b[1mTarget:\t\u001b[0m i am reasonable . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not being unreasonable .\n","\u001b[1mW-Pred:\t\u001b[0m i am being careful .\n","\u001b[1mF-Pred:\t\u001b[0m i am undressing .\n","\u001b[1mS-Pred:\t\u001b[0m i am not being unreasonable . \n","\n","G-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.604\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","S-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.604\n","\n","\n","\u001b[1mInput:\t\u001b[0m je cherche du travail .\n","\u001b[1mTarget:\t\u001b[0m i am looking for a job . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mW-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mF-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mS-Pred:\t\u001b[0m i am looking for work . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.655\tGleu: 0.556\tCustom Score: 0.834\n","\n","\n","\u001b[1mInput:\t\u001b[0m je vais bien et toi ?\n","\u001b[1mTarget:\t\u001b[0m i am fine . how about you ? \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am fine for you ?\n","\u001b[1mW-Pred:\t\u001b[0m i am fine !\n","\u001b[1mF-Pred:\t\u001b[0m i am dying to see you ?\n","\u001b[1mS-Pred:\t\u001b[0m i am fine . \n","\n","G-Scores:\tBleu: 0.536\tGleu: 0.318\tCustom Score: 0.482\n","W-Scores:\tBleu: 0.264\tGleu: 0.273\tCustom Score: 0.266\n","F-Scores:\tBleu: 0.423\tGleu: 0.182\tCustom Score: 0.486\n","S-Scores:\tBleu: 0.264\tGleu: 0.273\tCustom Score: 0.266\n","\n","\n","\u001b[1mInput:\t\u001b[0m il n est pas gentil avec elle .\n","\u001b[1mTarget:\t\u001b[0m he is not kind to her . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is not my age .\n","\u001b[1mW-Pred:\t\u001b[0m he is not what he used to be .\n","\u001b[1mF-Pred:\t\u001b[0m he is not at his father .\n","\u001b[1mS-Pred:\t\u001b[0m he is not kind . \n","\n","G-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.818\n","W-Scores:\tBleu: 0.500\tGleu: 0.269\tCustom Score: 0.659\n","F-Scores:\tBleu: 0.500\tGleu: 0.333\tCustom Score: 0.848\n","S-Scores:\tBleu: 0.607\tGleu: 0.556\tCustom Score: 0.594\n","\n","\n","\u001b[1mInput:\t\u001b[0m ils n ont pas toujours raison .\n","\u001b[1mTarget:\t\u001b[0m they are not always right . \n","\n","\u001b[1mG-Pred:\t\u001b[0m they are not always right .\n","\u001b[1mW-Pred:\t\u001b[0m they are right behind you .\n","\u001b[1mF-Pred:\t\u001b[0m they are not always right .\n","\u001b[1mS-Pred:\t\u001b[0m they are not always there . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.600\tGleu: 0.286\tCustom Score: 0.850\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.800\tGleu: 0.714\tCustom Score: 0.779\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne suis pas en service aujourd hui .\n","\u001b[1mTarget:\t\u001b[0m i am not on duty today . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not a saint .\n","\u001b[1mW-Pred:\t\u001b[0m i am not sure .\n","\u001b[1mF-Pred:\t\u001b[0m i am not taking in the soccer thing .\n","\u001b[1mS-Pred:\t\u001b[0m i am off duty today . \n","\n","G-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.452\n","W-Scores:\tBleu: 0.455\tGleu: 0.333\tCustom Score: 0.425\n","F-Scores:\tBleu: 0.375\tGleu: 0.231\tCustom Score: 0.339\n","S-Scores:\tBleu: 0.655\tGleu: 0.333\tCustom Score: 0.575\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis epuise .\n","\u001b[1mTarget:\t\u001b[0m i am worn out . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am exhausted .\n","\u001b[1mW-Pred:\t\u001b[0m i am exhausted .\n","\u001b[1mF-Pred:\t\u001b[0m i am desperate .\n","\u001b[1mS-Pred:\t\u001b[0m i am exhausted . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes plus grands que moi .\n","\u001b[1mTarget:\t\u001b[0m you are taller than me . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are taller than our friend .\n","\u001b[1mW-Pred:\t\u001b[0m you are taller than me .\n","\u001b[1mF-Pred:\t\u001b[0m you are taller than i am .\n","\u001b[1mS-Pred:\t\u001b[0m you are taller than i . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.556\tCustom Score: 0.947\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 0.667\tGleu: 0.556\tCustom Score: 0.763\n","S-Scores:\tBleu: 0.800\tGleu: 0.714\tCustom Score: 0.902\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis desole d etre en retard .\n","\u001b[1mTarget:\t\u001b[0m i am sorry i am so late . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am sorry for being late .\n","\u001b[1mW-Pred:\t\u001b[0m i am going to send tom some work .\n","\u001b[1mF-Pred:\t\u001b[0m i am sorry about my mistake .\n","\u001b[1mS-Pred:\t\u001b[0m i am sorry for being late . \n","\n","G-Scores:\tBleu: 0.564\tGleu: 0.318\tCustom Score: 0.764\n","W-Scores:\tBleu: 0.250\tGleu: 0.115\tCustom Score: 0.805\n","F-Scores:\tBleu: 0.423\tGleu: 0.273\tCustom Score: 0.668\n","S-Scores:\tBleu: 0.564\tGleu: 0.318\tCustom Score: 0.764\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis de shizuoka .\n","\u001b[1mTarget:\t\u001b[0m i am from shizuoka . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am touched .\n","\u001b[1mW-Pred:\t\u001b[0m i am doing this night .\n","\u001b[1mF-Pred:\t\u001b[0m i am worried about that .\n","\u001b[1mS-Pred:\t\u001b[0m i am from . \n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis serieuse .\n","\u001b[1mTarget:\t\u001b[0m i am being serious . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not bluffing .\n","\u001b[1mW-Pred:\t\u001b[0m i am being serious .\n","\u001b[1mF-Pred:\t\u001b[0m i am contagious .\n","\u001b[1mS-Pred:\t\u001b[0m i am not bluffing . \n","\n","G-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle est son amie .\n","\u001b[1mTarget:\t\u001b[0m she is his friend . \n","\n","\u001b[1mG-Pred:\t\u001b[0m she is her friend .\n","\u001b[1mW-Pred:\t\u001b[0m she is a gifted artist .\n","\u001b[1mF-Pred:\t\u001b[0m she is a real gossip .\n","\u001b[1mS-Pred:\t\u001b[0m she is her friend . \n","\n","G-Scores:\tBleu: 0.750\tGleu: 0.400\tCustom Score: 0.917\n","W-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.354\n","F-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.354\n","S-Scores:\tBleu: 0.750\tGleu: 0.400\tCustom Score: 0.917\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne suis pas du tout fatigue .\n","\u001b[1mTarget:\t\u001b[0m i am not tired at all . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not tired at all .\n","\u001b[1mW-Pred:\t\u001b[0m i am not sure anymore .\n","\u001b[1mF-Pred:\t\u001b[0m i am not tired .\n","\u001b[1mS-Pred:\t\u001b[0m i am not a bit tired . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.939\n","F-Scores:\tBleu: 0.607\tGleu: 0.556\tCustom Score: 0.594\n","S-Scores:\tBleu: 0.667\tGleu: 0.389\tCustom Score: 0.597\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis etudiant .\n","\u001b[1mTarget:\t\u001b[0m i am a university student . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am a student .\n","\u001b[1mW-Pred:\t\u001b[0m i am a teacher .\n","\u001b[1mF-Pred:\t\u001b[0m i am a student .\n","\u001b[1mS-Pred:\t\u001b[0m i am a student . \n","\n","G-Scores:\tBleu: 0.779\tGleu: 0.500\tCustom Score: 0.709\n","W-Scores:\tBleu: 0.584\tGleu: 0.429\tCustom Score: 0.931\n","F-Scores:\tBleu: 0.779\tGleu: 0.500\tCustom Score: 0.709\n","S-Scores:\tBleu: 0.779\tGleu: 0.500\tCustom Score: 0.709\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous sommes des hommes occupes .\n","\u001b[1mTarget:\t\u001b[0m we are busy men . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are proud of you .\n","\u001b[1mW-Pred:\t\u001b[0m we are in love .\n","\u001b[1mF-Pred:\t\u001b[0m we are flattered .\n","\u001b[1mS-Pred:\t\u001b[0m we are busy . \n","\n","G-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.354\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.717\tGleu: 0.600\tCustom Score: 0.687\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous n en avons pas encore termine .\n","\u001b[1mTarget:\t\u001b[0m we are not done yet . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are not done yet .\n","\u001b[1mW-Pred:\t\u001b[0m we are not going .\n","\u001b[1mF-Pred:\t\u001b[0m we are not done .\n","\u001b[1mS-Pred:\t\u001b[0m we are not finished yet . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.584\tGleu: 0.429\tCustom Score: 0.726\n","F-Scores:\tBleu: 0.779\tGleu: 0.714\tCustom Score: 0.763\n","S-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.725\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne suis pas du tout convaincu .\n","\u001b[1mTarget:\t\u001b[0m i am not convinced at all . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not convinced at all .\n","\u001b[1mW-Pred:\t\u001b[0m i am not sure anymore .\n","\u001b[1mF-Pred:\t\u001b[0m i am not sure why .\n","\u001b[1mS-Pred:\t\u001b[0m i am not at all . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.959\n","F-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.816\n","S-Scores:\tBleu: 0.819\tGleu: 0.500\tCustom Score: 0.739\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous vous amusez n est ce pas ?\n","\u001b[1mTarget:\t\u001b[0m you are enjoying yourself are not you ? \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are enjoying yourself are not you ?\n","\u001b[1mW-Pred:\t\u001b[0m you are enjoying yourselves are not you ?\n","\u001b[1mF-Pred:\t\u001b[0m you are enjoying yourself are not you ?\n","\u001b[1mS-Pred:\t\u001b[0m you are enjoying yourselves are not you ? \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.857\tGleu: 0.545\tCustom Score: 0.928\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.857\tGleu: 0.545\tCustom Score: 0.928\n","\n","\n","\u001b[1mInput:\t\u001b[0m t es bourre .\n","\u001b[1mTarget:\t\u001b[0m you are sloshed . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are temperamental .\n","\u001b[1mW-Pred:\t\u001b[0m you are loaded .\n","\u001b[1mF-Pred:\t\u001b[0m you are annoying .\n","\u001b[1mS-Pred:\t\u001b[0m you are smashed . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.754\n","\n","\n","\u001b[1mInput:\t\u001b[0m tu es tellement idiote !\n","\u001b[1mTarget:\t\u001b[0m you are such an idiot ! \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are such an idiot !\n","\u001b[1mW-Pred:\t\u001b[0m you are so picky !\n","\u001b[1mF-Pred:\t\u001b[0m you are so picky are he t he !\n","\u001b[1mS-Pred:\t\u001b[0m you are so an . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.389\tGleu: 0.214\tCustom Score: 0.472\n","F-Scores:\tBleu: 0.250\tGleu: 0.115\tCustom Score: 0.343\n","S-Scores:\tBleu: 0.584\tGleu: 0.286\tCustom Score: 0.636\n","\n","\n","\u001b[1mInput:\t\u001b[0m il a trois ans de plus que moi .\n","\u001b[1mTarget:\t\u001b[0m he is three years older than i am . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is two years younger than me .\n","\u001b[1mW-Pred:\t\u001b[0m he is at home every day than his car .\n","\u001b[1mF-Pred:\t\u001b[0m he is three years older than me .\n","\u001b[1mS-Pred:\t\u001b[0m he is three years older than me . \n","\n","G-Scores:\tBleu: 0.495\tGleu: 0.192\tCustom Score: 0.828\n","W-Scores:\tBleu: 0.333\tGleu: 0.133\tCustom Score: 0.418\n","F-Scores:\tBleu: 0.743\tGleu: 0.692\tCustom Score: 0.854\n","S-Scores:\tBleu: 0.743\tGleu: 0.692\tCustom Score: 0.854\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous en avons termine .\n","\u001b[1mTarget:\t\u001b[0m we are all done . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are through .\n","\u001b[1mW-Pred:\t\u001b[0m we are done .\n","\u001b[1mF-Pred:\t\u001b[0m we are finished already .\n","\u001b[1mS-Pred:\t\u001b[0m we are finished . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.717\tGleu: 0.400\tCustom Score: 0.637\n","F-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.574\n","S-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous n allez jamais le croire .\n","\u001b[1mTarget:\t\u001b[0m you are never going to believe this . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are not going to believe this .\n","\u001b[1mW-Pred:\t\u001b[0m you are not very tidy .\n","\u001b[1mF-Pred:\t\u001b[0m you are not telling to truth .\n","\u001b[1mS-Pred:\t\u001b[0m you are going to believe this . \n","\n","G-Scores:\tBleu: 0.857\tGleu: 0.591\tCustom Score: 0.980\n","W-Scores:\tBleu: 0.268\tGleu: 0.136\tCustom Score: 0.762\n","F-Scores:\tBleu: 0.423\tGleu: 0.182\tCustom Score: 0.888\n","S-Scores:\tBleu: 0.846\tGleu: 0.591\tCustom Score: 0.783\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle n est pas toujours heureuse .\n","\u001b[1mTarget:\t\u001b[0m she is not always happy . \n","\n","\u001b[1mG-Pred:\t\u001b[0m she is not always happy .\n","\u001b[1mW-Pred:\t\u001b[0m she is not very happy .\n","\u001b[1mF-Pred:\t\u001b[0m she is not happy .\n","\u001b[1mS-Pred:\t\u001b[0m she is not always . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.933\n","F-Scores:\tBleu: 0.779\tGleu: 0.500\tCustom Score: 0.709\n","S-Scores:\tBleu: 0.779\tGleu: 0.714\tCustom Score: 0.763\n","\n","\n","\u001b[1mInput:\t\u001b[0m tu es tres elegante .\n","\u001b[1mTarget:\t\u001b[0m you are very sophisticated . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mW-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mF-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mS-Pred:\t\u001b[0m you are very stylish . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.750\tGleu: 0.600\tCustom Score: 0.863\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne suis pas du tout fatigue .\n","\u001b[1mTarget:\t\u001b[0m i am not at all tired . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not tired at all .\n","\u001b[1mW-Pred:\t\u001b[0m i am not sure anymore .\n","\u001b[1mF-Pred:\t\u001b[0m i am not tired .\n","\u001b[1mS-Pred:\t\u001b[0m i am not a bit tired . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 0.556\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.939\n","F-Scores:\tBleu: 0.607\tGleu: 0.389\tCustom Score: 0.552\n","S-Scores:\tBleu: 0.667\tGleu: 0.389\tCustom Score: 0.597\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis desole nous avons ete devalises .\n","\u001b[1mTarget:\t\u001b[0m i am sorry we are completely sold out . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am sorry we are in discuss some problem .\n","\u001b[1mW-Pred:\t\u001b[0m i am sorry i hurt you .\n","\u001b[1mF-Pred:\t\u001b[0m i am sorry we are completely sold out .\n","\u001b[1mS-Pred:\t\u001b[0m i am sorry we are sold sold out . \n","\n","G-Scores:\tBleu: 0.556\tGleu: 0.467\tCustom Score: 0.533\n","W-Scores:\tBleu: 0.358\tGleu: 0.231\tCustom Score: 0.589\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.875\tGleu: 0.654\tCustom Score: 0.720\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous planifions de faire seulement cela .\n","\u001b[1mTarget:\t\u001b[0m we are planning to do just that . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are planning to do too .\n","\u001b[1mW-Pred:\t\u001b[0m we are not free .\n","\u001b[1mF-Pred:\t\u001b[0m we are planning to do questions .\n","\u001b[1mS-Pred:\t\u001b[0m we are to to do that . \n","\n","G-Scores:\tBleu: 0.705\tGleu: 0.636\tCustom Score: 0.930\n","W-Scores:\tBleu: 0.236\tGleu: 0.136\tCustom Score: 0.933\n","F-Scores:\tBleu: 0.705\tGleu: 0.636\tCustom Score: 0.688\n","S-Scores:\tBleu: 0.705\tGleu: 0.318\tCustom Score: 0.509\n","\n","\n","\u001b[1mInput:\t\u001b[0m tu es fou .\n","\u001b[1mTarget:\t\u001b[0m you are crazy . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are demented .\n","\u001b[1mW-Pred:\t\u001b[0m you are charming .\n","\u001b[1mF-Pred:\t\u001b[0m you are silly .\n","\u001b[1mS-Pred:\t\u001b[0m you are demented . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.807\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.865\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.807\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous sommes vieux amis .\n","\u001b[1mTarget:\t\u001b[0m we are friends from way back . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are friends now .\n","\u001b[1mW-Pred:\t\u001b[0m we are in love .\n","\u001b[1mF-Pred:\t\u001b[0m we are friends from .\n","\u001b[1mS-Pred:\t\u001b[0m we are old friends . \n","\n","G-Scores:\tBleu: 0.455\tGleu: 0.333\tCustom Score: 0.575\n","W-Scores:\tBleu: 0.303\tGleu: 0.167\tCustom Score: 0.439\n","F-Scores:\tBleu: 0.607\tGleu: 0.556\tCustom Score: 0.594\n","S-Scores:\tBleu: 0.455\tGleu: 0.222\tCustom Score: 0.397\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis un peu occupe .\n","\u001b[1mTarget:\t\u001b[0m i am a little busy . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am a bit jealous .\n","\u001b[1mW-Pred:\t\u001b[0m i am a little bit drunk .\n","\u001b[1mF-Pred:\t\u001b[0m i am a bit busy .\n","\u001b[1mS-Pred:\t\u001b[0m i am a bit busy . \n","\n","G-Scores:\tBleu: 0.600\tGleu: 0.429\tCustom Score: 0.880\n","W-Scores:\tBleu: 0.667\tGleu: 0.556\tCustom Score: 0.639\n","F-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.967\n","S-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.967\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis pret a partir maintenant .\n","\u001b[1mTarget:\t\u001b[0m i am ready to go now . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am ready to go from ready .\n","\u001b[1mW-Pred:\t\u001b[0m i am ready to go now .\n","\u001b[1mF-Pred:\t\u001b[0m i am ready to go .\n","\u001b[1mS-Pred:\t\u001b[0m i am ready to leave now . \n","\n","G-Scores:\tBleu: 0.714\tGleu: 0.636\tCustom Score: 0.595\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 0.819\tGleu: 0.778\tCustom Score: 0.808\n","S-Scores:\tBleu: 0.833\tGleu: 0.611\tCustom Score: 0.968\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis epuise .\n","\u001b[1mTarget:\t\u001b[0m i am worn out . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am exhausted .\n","\u001b[1mW-Pred:\t\u001b[0m i am exhausted .\n","\u001b[1mF-Pred:\t\u001b[0m i am desperate .\n","\u001b[1mS-Pred:\t\u001b[0m i am exhausted . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","\n","\n","\u001b[1mInput:\t\u001b[0m il souffre d une maladie grave .\n","\u001b[1mTarget:\t\u001b[0m he is suffering from a serious illness . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is cleaning their rifle .\n","\u001b[1mW-Pred:\t\u001b[0m he is handicapped by poor hearing .\n","\u001b[1mF-Pred:\t\u001b[0m he is suffering from a serious illness .\n","\u001b[1mS-Pred:\t\u001b[0m he is suffering from a serious disease . \n","\n","G-Scores:\tBleu: 0.268\tGleu: 0.136\tCustom Score: 0.235\n","W-Scores:\tBleu: 0.282\tGleu: 0.136\tCustom Score: 0.382\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.857\tGleu: 0.818\tCustom Score: 0.967\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous avons termine .\n","\u001b[1mTarget:\t\u001b[0m we are through . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are through .\n","\u001b[1mW-Pred:\t\u001b[0m we are getting warmer .\n","\u001b[1mF-Pred:\t\u001b[0m we are finished .\n","\u001b[1mS-Pred:\t\u001b[0m we are finished . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","\n","\n","\u001b[1mInput:\t\u001b[0m ce n est qu un enfant .\n","\u001b[1mTarget:\t\u001b[0m he is just a kid . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is just a child .\n","\u001b[1mW-Pred:\t\u001b[0m he is the spitting one of us .\n","\u001b[1mF-Pred:\t\u001b[0m he is every not a kid anymore .\n","\u001b[1mS-Pred:\t\u001b[0m he is just a child . \n","\n","G-Scores:\tBleu: 0.800\tGleu: 0.714\tCustom Score: 0.969\n","W-Scores:\tBleu: 0.286\tGleu: 0.136\tCustom Score: 0.597\n","F-Scores:\tBleu: 0.571\tGleu: 0.273\tCustom Score: 0.938\n","S-Scores:\tBleu: 0.800\tGleu: 0.714\tCustom Score: 0.969\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne suis pas d ici .\n","\u001b[1mTarget:\t\u001b[0m i am not from here . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not from here .\n","\u001b[1mW-Pred:\t\u001b[0m i am not the boss .\n","\u001b[1mF-Pred:\t\u001b[0m i am not here to succeed .\n","\u001b[1mS-Pred:\t\u001b[0m i am not here on here . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.600\tGleu: 0.429\tCustom Score: 0.557\n","F-Scores:\tBleu: 0.667\tGleu: 0.389\tCustom Score: 0.597\n","S-Scores:\tBleu: 0.667\tGleu: 0.389\tCustom Score: 0.497\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis saoul .\n","\u001b[1mTarget:\t\u001b[0m i am loaded . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am drunk .\n","\u001b[1mW-Pred:\t\u001b[0m i am broke .\n","\u001b[1mF-Pred:\t\u001b[0m i am drunk .\n","\u001b[1mS-Pred:\t\u001b[0m i am drunk . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","\n","\n","\u001b[1mInput:\t\u001b[0m il souffre d un rhume .\n","\u001b[1mTarget:\t\u001b[0m he is suffering from a cold . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is a bit to china .\n","\u001b[1mW-Pred:\t\u001b[0m he is suffering from a cold .\n","\u001b[1mF-Pred:\t\u001b[0m he is started of dogs .\n","\u001b[1mS-Pred:\t\u001b[0m he is suffering from a cold from . \n","\n","G-Scores:\tBleu: 0.500\tGleu: 0.222\tCustom Score: 0.431\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 0.327\tGleu: 0.167\tCustom Score: 0.287\n","S-Scores:\tBleu: 0.857\tGleu: 0.818\tCustom Score: 0.747\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis gene .\n","\u001b[1mTarget:\t\u001b[0m i am uncomfortable . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am embarrassed .\n","\u001b[1mW-Pred:\t\u001b[0m i am impatient .\n","\u001b[1mF-Pred:\t\u001b[0m i am uncomfortable .\n","\u001b[1mS-Pred:\t\u001b[0m i am embarrassed . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.826\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.783\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.826\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis serieuse .\n","\u001b[1mTarget:\t\u001b[0m i am being serious . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not bluffing .\n","\u001b[1mW-Pred:\t\u001b[0m i am being serious .\n","\u001b[1mF-Pred:\t\u001b[0m i am contagious .\n","\u001b[1mS-Pred:\t\u001b[0m i am not bluffing . \n","\n","G-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes deux fois plus forts que moi .\n","\u001b[1mTarget:\t\u001b[0m you are twice as strong as i am . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are twice as strong as i am .\n","\u001b[1mW-Pred:\t\u001b[0m you are twice as strong as me .\n","\u001b[1mF-Pred:\t\u001b[0m you are twice as strong as me .\n","\u001b[1mS-Pred:\t\u001b[0m you are twice as strong as i . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.743\tGleu: 0.692\tCustom Score: 0.854\n","F-Scores:\tBleu: 0.743\tGleu: 0.692\tCustom Score: 0.854\n","S-Scores:\tBleu: 0.867\tGleu: 0.846\tCustom Score: 0.862\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous sommes en train de perdre .\n","\u001b[1mTarget:\t\u001b[0m we are losing it . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are losing .\n","\u001b[1mW-Pred:\t\u001b[0m we are in love .\n","\u001b[1mF-Pred:\t\u001b[0m we are losing .\n","\u001b[1mS-Pred:\t\u001b[0m we are losing . \n","\n","G-Scores:\tBleu: 0.717\tGleu: 0.600\tCustom Score: 0.687\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.717\tGleu: 0.600\tCustom Score: 0.687\n","S-Scores:\tBleu: 0.717\tGleu: 0.600\tCustom Score: 0.687\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous retournons en arriere .\n","\u001b[1mTarget:\t\u001b[0m we are going back . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are going back .\n","\u001b[1mW-Pred:\t\u001b[0m we are getting close .\n","\u001b[1mF-Pred:\t\u001b[0m we are going back .\n","\u001b[1mS-Pred:\t\u001b[0m we are turning back . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.782\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.750\tGleu: 0.400\tCustom Score: 0.806\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous n en avons pas fini .\n","\u001b[1mTarget:\t\u001b[0m we are not done . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are not done yet .\n","\u001b[1mW-Pred:\t\u001b[0m we are not done .\n","\u001b[1mF-Pred:\t\u001b[0m we are not done .\n","\u001b[1mS-Pred:\t\u001b[0m we are not finished . \n","\n","G-Scores:\tBleu: 0.800\tGleu: 0.714\tCustom Score: 0.779\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.750\tGleu: 0.600\tCustom Score: 0.713\n","\n","\n","\u001b[1mInput:\t\u001b[0m je me deshabille .\n","\u001b[1mTarget:\t\u001b[0m i am getting undressed . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am undressing .\n","\u001b[1mW-Pred:\t\u001b[0m i am ruined .\n","\u001b[1mF-Pred:\t\u001b[0m i am losing .\n","\u001b[1mS-Pred:\t\u001b[0m i am undressing undressed . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.699\n","W-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.587\n","S-Scores:\tBleu: 0.750\tGleu: 0.400\tCustom Score: 0.662\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous sommes sinceres .\n","\u001b[1mTarget:\t\u001b[0m we are sincere . \n","\n","\u001b[1mG-Pred:\t\u001b[0m we are sincere .\n","\u001b[1mW-Pred:\t\u001b[0m we are unlucky .\n","\u001b[1mF-Pred:\t\u001b[0m we are sincere .\n","\u001b[1mS-Pred:\t\u001b[0m we is sincere . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.667\tGleu: 0.333\tCustom Score: 0.798\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle est sympa avec moi .\n","\u001b[1mTarget:\t\u001b[0m she is nice to me . \n","\n","\u001b[1mG-Pred:\t\u001b[0m she is completely old .\n","\u001b[1mW-Pred:\t\u001b[0m she is very annoyed with her daughter .\n","\u001b[1mF-Pred:\t\u001b[0m she is a bit naive .\n","\u001b[1mS-Pred:\t\u001b[0m she is being to me . \n","\n","G-Scores:\tBleu: 0.389\tGleu: 0.214\tCustom Score: 0.346\n","W-Scores:\tBleu: 0.286\tGleu: 0.136\tCustom Score: 0.690\n","F-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.688\n","S-Scores:\tBleu: 0.800\tGleu: 0.429\tCustom Score: 0.707\n","\n","\n","\u001b[1mInput:\t\u001b[0m c est un petit gars intelligent .\n","\u001b[1mTarget:\t\u001b[0m he is a smart little feller . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is a fine young lad .\n","\u001b[1mW-Pred:\t\u001b[0m he is a very imaginative writer .\n","\u001b[1mF-Pred:\t\u001b[0m he is a hunk .\n","\u001b[1mS-Pred:\t\u001b[0m he is a little smart boy . \n","\n","G-Scores:\tBleu: 0.500\tGleu: 0.333\tCustom Score: 0.785\n","W-Scores:\tBleu: 0.500\tGleu: 0.333\tCustom Score: 0.741\n","F-Scores:\tBleu: 0.455\tGleu: 0.333\tCustom Score: 0.566\n","S-Scores:\tBleu: 0.833\tGleu: 0.444\tCustom Score: 0.889\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est riche .\n","\u001b[1mTarget:\t\u001b[0m he is well off . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is rich .\n","\u001b[1mW-Pred:\t\u001b[0m he is a dj .\n","\u001b[1mF-Pred:\t\u001b[0m he is rich .\n","\u001b[1mS-Pred:\t\u001b[0m he is rich . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","S-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","\n","\n","\u001b[1mInput:\t\u001b[0m il l a fait auparavant .\n","\u001b[1mTarget:\t\u001b[0m he is done this before . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is done it before .\n","\u001b[1mW-Pred:\t\u001b[0m he is equal to work .\n","\u001b[1mF-Pred:\t\u001b[0m he is always complaining about the job .\n","\u001b[1mS-Pred:\t\u001b[0m he is done it before . \n","\n","G-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.940\n","W-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.527\n","F-Scores:\tBleu: 0.286\tGleu: 0.136\tCustom Score: 0.401\n","S-Scores:\tBleu: 0.800\tGleu: 0.500\tCustom Score: 0.940\n","\n","\n","\u001b[1mInput:\t\u001b[0m tu as raison .\n","\u001b[1mTarget:\t\u001b[0m you are correct . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are correct .\n","\u001b[1mW-Pred:\t\u001b[0m you are turning red .\n","\u001b[1mF-Pred:\t\u001b[0m you are right .\n","\u001b[1mS-Pred:\t\u001b[0m you are right . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.786\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.786\n","\n","\n","\u001b[1mInput:\t\u001b[0m il va bien .\n","\u001b[1mTarget:\t\u001b[0m he is doing well . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is fine .\n","\u001b[1mW-Pred:\t\u001b[0m he is still single .\n","\u001b[1mF-Pred:\t\u001b[0m he is getting better .\n","\u001b[1mS-Pred:\t\u001b[0m he is all right . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.808\n","S-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.694\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis dans la maison .\n","\u001b[1mTarget:\t\u001b[0m i am at home . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am in a house .\n","\u001b[1mW-Pred:\t\u001b[0m i am on the city .\n","\u001b[1mF-Pred:\t\u001b[0m i am going to the police .\n","\u001b[1mS-Pred:\t\u001b[0m i am in the house . \n","\n","G-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.578\n","W-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.354\n","F-Scores:\tBleu: 0.333\tGleu: 0.167\tCustom Score: 0.292\n","S-Scores:\tBleu: 0.400\tGleu: 0.214\tCustom Score: 0.578\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis content de ma nouvelle veste .\n","\u001b[1mTarget:\t\u001b[0m i am pleased with my new bathing suit . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am pleased with his job .\n","\u001b[1mW-Pred:\t\u001b[0m i am going to be your teacher .\n","\u001b[1mF-Pred:\t\u001b[0m i am pretty busy is waiting .\n","\u001b[1mS-Pred:\t\u001b[0m i am pleased with my new jacket . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.385\tCustom Score: 0.697\n","W-Scores:\tBleu: 0.248\tGleu: 0.115\tCustom Score: 0.614\n","F-Scores:\tBleu: 0.239\tGleu: 0.115\tCustom Score: 0.208\n","S-Scores:\tBleu: 0.743\tGleu: 0.692\tCustom Score: 0.854\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est en train de lire un roman .\n","\u001b[1mTarget:\t\u001b[0m he is reading a novel now . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is in his class .\n","\u001b[1mW-Pred:\t\u001b[0m he is on the radio .\n","\u001b[1mF-Pred:\t\u001b[0m he is reading a novel .\n","\u001b[1mS-Pred:\t\u001b[0m he is reading a novel right now . \n","\n","G-Scores:\tBleu: 0.327\tGleu: 0.167\tCustom Score: 0.287\n","W-Scores:\tBleu: 0.327\tGleu: 0.167\tCustom Score: 0.287\n","F-Scores:\tBleu: 0.819\tGleu: 0.778\tCustom Score: 0.808\n","S-Scores:\tBleu: 0.857\tGleu: 0.682\tCustom Score: 0.813\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes incroyables .\n","\u001b[1mTarget:\t\u001b[0m you are amazing . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are incredible .\n","\u001b[1mW-Pred:\t\u001b[0m you are resilient .\n","\u001b[1mF-Pred:\t\u001b[0m you are funny .\n","\u001b[1mS-Pred:\t\u001b[0m you are incredible . \n","\n","G-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.987\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.780\n","S-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.987\n","\n","\n","\u001b[1mInput:\t\u001b[0m je cherche du travail .\n","\u001b[1mTarget:\t\u001b[0m i am looking for a job . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mW-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mF-Pred:\t\u001b[0m i am looking for a job .\n","\u001b[1mS-Pred:\t\u001b[0m i am looking for work . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.655\tGleu: 0.556\tCustom Score: 0.834\n","\n","\n","\u001b[1mInput:\t\u001b[0m il porte ses livres sous son bras .\n","\u001b[1mTarget:\t\u001b[0m he is holding his books under his arm . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is his narita for them .\n","\u001b[1mW-Pred:\t\u001b[0m he is watching tv every night .\n","\u001b[1mF-Pred:\t\u001b[0m he is decided to leave his father .\n","\u001b[1mS-Pred:\t\u001b[0m he is holding his books under his . \n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il n est pas idiot .\n","\u001b[1mTarget:\t\u001b[0m he is not stupid . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is not stupid .\n","\u001b[1mW-Pred:\t\u001b[0m he is not religious .\n","\u001b[1mF-Pred:\t\u001b[0m he is not stupid .\n","\u001b[1mS-Pred:\t\u001b[0m he is no fool . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.750\tGleu: 0.600\tCustom Score: 0.713\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.876\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes tres elegante .\n","\u001b[1mTarget:\t\u001b[0m you are very sophisticated . \n","\n","\u001b[1mG-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mW-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mF-Pred:\t\u001b[0m you are very sophisticated .\n","\u001b[1mS-Pred:\t\u001b[0m you are very stylish . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","F-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","S-Scores:\tBleu: 0.750\tGleu: 0.600\tCustom Score: 0.863\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis en retard .\n","\u001b[1mTarget:\t\u001b[0m i am behind schedule . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am early .\n","\u001b[1mW-Pred:\t\u001b[0m i am eating now .\n","\u001b[1mF-Pred:\t\u001b[0m i am in way my light .\n","\u001b[1mS-Pred:\t\u001b[0m i am late . \n","\n","G-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","W-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.450\n","F-Scores:\tBleu: 0.333\tGleu: 0.167\tCustom Score: 0.292\n","S-Scores:\tBleu: 0.478\tGleu: 0.300\tCustom Score: 0.433\n","\n","\n","\u001b[1mInput:\t\u001b[0m je plaisante .\n","\u001b[1mTarget:\t\u001b[0m i am joking . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am joking .\n","\u001b[1mW-Pred:\t\u001b[0m i am not .\n","\u001b[1mF-Pred:\t\u001b[0m i am falling .\n","\u001b[1mS-Pred:\t\u001b[0m i am just kidding . \n","\n","G-Scores:\tBleu: 1.000\tGleu: 1.000\tCustom Score: 1.000\n","W-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","F-Scores:\tBleu: 0.667\tGleu: 0.500\tCustom Score: 0.625\n","S-Scores:\tBleu: 0.500\tGleu: 0.300\tCustom Score: 0.837\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est fort comme un cheval .\n","\u001b[1mTarget:\t\u001b[0m he is as strong as a horse . \n","\n","\u001b[1mG-Pred:\t\u001b[0m he is a very been a doctor .\n","\u001b[1mW-Pred:\t\u001b[0m he is very fond of best longer music .\n","\u001b[1mF-Pred:\t\u001b[0m he is unfit for the job .\n","\u001b[1mS-Pred:\t\u001b[0m he is strong as a horse . \n","\n","G-Scores:\tBleu: 0.429\tGleu: 0.182\tCustom Score: 0.367\n","W-Scores:\tBleu: 0.250\tGleu: 0.115\tCustom Score: 0.339\n","F-Scores:\tBleu: 0.282\tGleu: 0.136\tCustom Score: 0.246\n","S-Scores:\tBleu: 0.846\tGleu: 0.591\tCustom Score: 0.783\n","\n","\n","\u001b[1mInput:\t\u001b[0m je ne vais pas bien du tout .\n","\u001b[1mTarget:\t\u001b[0m i am not well at all . \n","\n","\u001b[1mG-Pred:\t\u001b[0m i am not giving up .\n","\u001b[1mW-Pred:\t\u001b[0m i am not going to stop yet .\n","\u001b[1mF-Pred:\t\u001b[0m i am not going to waste in here .\n","\u001b[1mS-Pred:\t\u001b[0m i am not at at . \n","\n","G-Scores:\tBleu: 0.491\tGleu: 0.333\tCustom Score: 0.452\n","W-Scores:\tBleu: 0.429\tGleu: 0.273\tCustom Score: 0.523\n","F-Scores:\tBleu: 0.375\tGleu: 0.231\tCustom Score: 0.749\n","S-Scores:\tBleu: 0.655\tGleu: 0.389\tCustom Score: 0.488\n","\n","\n","\u001b[1m\u001b[34mAvg G-Bleu Score  :\u001b[0m 0.684\n","\u001b[1m\u001b[34mAvg G-Gleu Score  :\u001b[0m 0.554\n","\u001b[1m\u001b[34mAvg G-Custom Score:\u001b[0m 0.749\n","\n","\n","\u001b[1m\u001b[34mAvg W-Bleu Score  :\u001b[0m 0.562\n","\u001b[1m\u001b[34mAvg W-Gleu Score  :\u001b[0m 0.417\n","\u001b[1m\u001b[34mAvg W-Custom Score:\u001b[0m 0.664\n","\n","\n","\u001b[1m\u001b[34mAvg F-Bleu Score  :\u001b[0m 0.628\n","\u001b[1m\u001b[34mAvg F-Gleu Score  :\u001b[0m 0.498\n","\u001b[1m\u001b[34mAvg F-Custom Score:\u001b[0m 0.688\n","\n","\n","\u001b[1m\u001b[34mAvg S-Bleu Score  :\u001b[0m 0.683\n","\u001b[1m\u001b[34mAvg S-Gleu Score  :\u001b[0m 0.490\n","\u001b[1m\u001b[34mAvg S-Custom Score:\u001b[0m 0.719\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e5LxuZ-sIeLH"},"source":["Evaluate on entire dataset"]},{"cell_type":"code","metadata":{"id":"X4Jnp__f4Kvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605725855298,"user_tz":300,"elapsed":129736,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"0c842089-b7aa-49ff-f8a6-1663c3ce5497"},"source":["evaluateAll(encoder1, attn_decoder1, all = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mEvaluation of Machine Translation Model\u001b[0m\n","\n","\n","\u001b[1m\u001b[34mAvg Bleu Score  :\u001b[0m 0.980\n","\u001b[1m\u001b[34mAvg Gleu Score  :\u001b[0m 0.967\n","\u001b[1m\u001b[34mAvg Custom Score:\u001b[0m 0.984\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t_iAa6E4KVqA"},"source":["Evaluate Google Translate on random sample of dataset\n"]},{"cell_type":"code","metadata":{"id":"CTWXqwubKYrG"},"source":["# Evaluates Google Translate Service on Dataset for n examples\n","# GT allows a limited number of translations per day - so can't run too many times or on entire dataset\n","# Input: n\n","# Output: none\n","\n","def eval_google_translate_randomly(n=20):\n","    print(bold+'Evaluation of Google Translate\\n')\n","    print('Evaluating',n,'examples...'+reset)\n","\n","    bleu_tracker = []\n","    gleu_tracker = []\n","    custom_tracker = []\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        ref = pair[1].split()\n","        pred = google_translate(pair[0])\n","        pred = normalizeString(pred)\n","        ref, pred = fix_punctuation(ref,pred.split())\n","        ref, pred = fix_contractions(ref,pred)\n"," \n","        print('\\n\\n')\n","        print(bold+'Input:\\t'+reset, pair[0])\n","        print(bold+'Target:\\t'+reset, ' '.join(ref))\n","        print(bold+'Pred:\\t'+reset, ' '.join(pred),'\\n')\n","        \n","        # requires ref to be a 2d list, pred 1d list\n","        bleu_one_gram = bleu([ref[:-1]],pred[:-1])\n","        bleu_tracker.append(bleu_one_gram)\n","        print(f'Bleu Score: {bleu_one_gram:.3f}')\n","\n","        gleu_one_gram = gleu([ref[:-1]],pred[:-1])\n","        gleu_tracker.append(gleu_one_gram)\n","        print(f'Gleu Score: {gleu_one_gram:.3f}')\n","        print(f'Avg Score:  {(gleu_one_gram*.25+bleu_one_gram*.75):.3f}') #weighted\n","        \n","        cs_score = 0\n","\n","        if bleu_one_gram < 1:\n","          try: # sometimes sims returns none\n","            sim_returns = similarities(ref,pred)\n","            cs_score = sim_returns[0]\n","            double_word_penalty = sim_returns[1]\n","            cust_score = custom_score(bleu_one_gram,gleu_one_gram,cs_score,double_word_penalty)\n","            print(bold_red_font_tag+'Custom Score: ',cust_score,reset)\n","            #print('\\n')\n","\n","          except KeyError:\n","            print('Cosine similarities: Word not found in embedding vocabulary')\n","            continue\n","        else:\n","          cust_score = custom_score(bleu_one_gram,gleu_one_gram,0,0)\n","          print(bold_red_font_tag+'Custom Score: ',cust_score,reset)\n","\n","        custom_tracker.append(cust_score)\n","\n","    print('\\n')\n","    print(f'{bold_blue_font_tag}Avg Bleu Score  :{reset} {sum(bleu_tracker)/len(bleu_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg Gleu Score  :{reset} {sum(gleu_tracker)/len(gleu_tracker):.3f}')\n","    print(f'{bold_blue_font_tag}Avg Custom Score:{reset} {sum(custom_tracker)/len(custom_tracker):.3f}')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbfr-hj6L2Jr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606171641947,"user_tz":300,"elapsed":8479,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"8ba957ad-6765-4ded-a702-580f152e000b"},"source":["eval_google_translate_randomly()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mEvaluation of Google Translate\n","\n","Evaluating 20 examples...\u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis introverti .\n","\u001b[1mTarget:\t\u001b[0m i am introverted .\n","\u001b[1mPred:\t\u001b[0m i am an introvert . \n","\n","Bleu Score: 0.500\n","Gleu Score: 0.300\n","Avg Score:  0.450\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['introverted', 'introvert', 0.7447564] \u001b[0m\n","\n","Semantic similarity bonus : + 0.29790256023406986\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.7479025602340699 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m c est un homme riche .\n","\u001b[1mTarget:\t\u001b[0m he is a man of wealth .\n","\u001b[1mPred:\t\u001b[0m he is a rich man . \n","\n","Bleu Score: 0.655\n","Gleu Score: 0.389\n","Avg Score:  0.588\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['wealth', 'rich', 0.45845908] \u001b[0m\n","\n","Semantic similarity bonus : + 0.1833836317062378\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.7718443057752492 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes tres elegante .\n","\u001b[1mTarget:\t\u001b[0m you are very sophisticated .\n","\u001b[1mPred:\t\u001b[0m you are very elegant . \n","\n","Bleu Score: 0.750\n","Gleu Score: 0.600\n","Avg Score:  0.713\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['sophisticated', 'elegant', 0.4337048] \u001b[0m\n","\n","Semantic similarity bonus : + 0.17348191738128663\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.8859819173812866 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes fort en colere .\n","\u001b[1mTarget:\t\u001b[0m you are very angry .\n","\u001b[1mPred:\t\u001b[0m you are very angry . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il fait du velo .\n","\u001b[1mTarget:\t\u001b[0m he is riding a bicycle .\n","\u001b[1mPred:\t\u001b[0m he is a biker . \n","\n","Bleu Score: 0.584\n","Gleu Score: 0.286\n","Avg Score:  0.510\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['bicycle', 'biker', 0.4419978] \u001b[0m\n","\u001b[1m   ['riding', 'biker', 0.37392926] \u001b[0m\n","\n","Semantic similarity bonus : + 0.32637082338333134\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.835874835289568 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle est toujours occupee les jours de semaine .\n","\u001b[1mTarget:\t\u001b[0m she is always busy on weekdays .\n","\u001b[1mPred:\t\u001b[0m it is always busy on weekdays . \n","\n","Bleu Score: 0.833\n","Gleu Score: 0.778\n","Avg Score:  0.819\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['she', 'it', 0.43182984] \u001b[0m\n","\n","Semantic similarity bonus : + 0.1727319359779358\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.9921763804223802 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est plein d ambition .\n","\u001b[1mTarget:\t\u001b[0m he is full of ambition .\n","\u001b[1mPred:\t\u001b[0m he is full of ambition . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est ecrivain .\n","\u001b[1mTarget:\t\u001b[0m he is a writer .\n","\u001b[1mPred:\t\u001b[0m he is a writer . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m t es une bonne fille .\n","\u001b[1mTarget:\t\u001b[0m you are a good person .\n","\u001b[1mPred:\t\u001b[0m you are a good person . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous mentez n est ce pas ?\n","\u001b[1mTarget:\t\u001b[0m you are lying are not you ?\n","\u001b[1mPred:\t\u001b[0m you are lying are not you ? \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est assis sur la chaise .\n","\u001b[1mTarget:\t\u001b[0m he is sitting on the chair .\n","\u001b[1mPred:\t\u001b[0m he sat on the chair . \n","\n","Bleu Score: 0.655\n","Gleu Score: 0.389\n","Avg Score:  0.588\n","\n","Semantic similarities using w2v:\n","\u001b[1m   ['sitting', 'sat', 0.7401665] \u001b[0m\n","   ['is', 'sat', 0.11343085]\n","\n","Semantic similarity bonus : + 0.29606659412384034\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.8845272681928518 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis heureux que tu sois la .\n","\u001b[1mTarget:\t\u001b[0m i am happy you are here .\n","\u001b[1mPred:\t\u001b[0m i am happy you came . \n","\n","Bleu Score: 0.655\n","Gleu Score: 0.556\n","Avg Score:  0.630\n","\n","Semantic similarities using w2v:\n","   ['here', 'came', 0.2541636]\n","   ['are', 'came', 0.19414374]\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.630127340735678 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes un drole de zozo .\n","\u001b[1mTarget:\t\u001b[0m you are a funny guy .\n","\u001b[1mPred:\t\u001b[0m you are a funny zozo . \n","\n","Bleu Score: 0.800\n","Gleu Score: 0.714\n","Avg Score:  0.779\n","Cosine similarities: Word not found in embedding vocabulary\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je suis parfaitement heureux .\n","\u001b[1mTarget:\t\u001b[0m i am perfectly happy .\n","\u001b[1mPred:\t\u001b[0m i am perfectly happy . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je vais a paris a l automne .\n","\u001b[1mTarget:\t\u001b[0m i am going to paris in the fall .\n","\u001b[1mPred:\t\u001b[0m i am going to betting in the fall . \n","\n","Bleu Score: 0.875\n","Gleu Score: 0.615\n","Avg Score:  0.810\n","\n","Semantic similarities using w2v:\n","   ['paris', 'betting', 0.0038579693]\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.8100961538461539 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m nous avons fini de parler .\n","\u001b[1mTarget:\t\u001b[0m we are done talking .\n","\u001b[1mPred:\t\u001b[0m we are done talking . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m je vais dormir .\n","\u001b[1mTarget:\t\u001b[0m i am going to sleep .\n","\u001b[1mPred:\t\u001b[0m i am going to sleep . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m il est vraiment en bonne forme .\n","\u001b[1mTarget:\t\u001b[0m he is really in good shape .\n","\u001b[1mPred:\t\u001b[0m he is really in good shape . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m elle n est pas poete mais romanciere .\n","\u001b[1mTarget:\t\u001b[0m she is not a poet but a novelist .\n","\u001b[1mPred:\t\u001b[0m she is not a poet but a novelist . \n","\n","Bleu Score: 1.000\n","Gleu Score: 1.000\n","Avg Score:  1.000\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  1.0 \u001b[0m\n","\n","\n","\n","\u001b[1mInput:\t\u001b[0m vous etes fort occupe .\n","\u001b[1mTarget:\t\u001b[0m you are very busy .\n","\u001b[1mPred:\t\u001b[0m you are busy . \n","\n","Bleu Score: 0.717\n","Gleu Score: 0.400\n","Avg Score:  0.637\n","\n","Semantic similarity bonus : + 0.0\n","Double word penalty:        - 0.0 \n","\n","\u001b[1m\u001b[31mCustom Score:  0.637398482930342 \u001b[0m\n","\n","\n","\u001b[1m\u001b[34mAvg Bleu Score  :\u001b[0m 0.851\n","\u001b[1m\u001b[34mAvg Gleu Score  :\u001b[0m 0.751\n","\u001b[1m\u001b[34mAvg Custom Score:\u001b[0m 0.905\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uW7RGSDl5XxA"},"source":["Try a custom sentence  \n","It should start with prefixes and be less than 10 words"]},{"cell_type":"code","metadata":{"id":"YHGl09YJtCbF"},"source":["sent = ['i am happy to see you','je suis content de te voir']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYrbYMBRtCeD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605733120344,"user_tz":300,"elapsed":383,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"7cd25435-62d3-47c5-82be-9f5edc1675ac"},"source":["print('Input:\\t\\t', sent[1])\n","print('Target:\\t\\t', sent[0])\n","output_words, attentions = evaluate(encoder1, attn_decoder1, sent[1])\n","output_sentence = ' '.join(output_words)\n","print('Prediction:\\t', output_sentence,'\\n')\n","ref = [sent[0].split()]\n","pred = output_sentence.split()[:-2]\n","\n","bleu_one_gram = bleu(ref,pred)\n","gleu_one_gram = gleu(ref,pred)\n","print(f'Bleu Score:\\t {bleu_one_gram:.2f}')\n","print(f'Gleu Score:\\t {gleu_one_gram:.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input:\t\t je suis content de te voir\n","Target:\t\t i am happy to see you\n","Prediction:\t i m glad to meet you . <EOS> \n","\n","Bleu Score:\t 0.50\n","Gleu Score:\t 0.17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rGgP-W8KD2O","executionInfo":{"status":"ok","timestamp":1606236632832,"user_tz":300,"elapsed":1191,"user":{"displayName":"Travis Twigg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZo1fSnuBhJ4Nhp2eV7YbBd38SXguQVkaE2XU8Nw=s64","userId":"16089971521895945039"}},"outputId":"1a3b96a1-60a0-49b6-a367-a2e93ec86a7b"},"source":["ref = ['i','am','happy','to','see','you']\n","pred = ['i','am','glad','to','see','you']\n","bleu_one_gram = bleu([ref],pred)\n","gleu_one_gram = gleu([ref],pred)\n","print(f'Bleu Score:\\t {bleu_one_gram:.2f}')\n","print(f'Gleu Score:\\t {gleu_one_gram:.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Bleu Score:\t 0.83\n","Gleu Score:\t 0.06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ohv59mrzTqeo"},"source":["# References  \n","\n","Robertson, S. (2020). NLP From Scratch: Translation with a Sequence to Sequence Network and Attention — PyTorch Tutorials 1.7.0 documentation. Https://Pytorch.Org. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"GEWXIfCDYMla"},"source":[""],"execution_count":null,"outputs":[]}]}